{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917660d6-7d13-4ccf-bee2-b7135fc34e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext kedro.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5020d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import typing as t\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.framework.project import settings\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c10c7-b6cc-4022-9fac-b70b58df96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_path = str(Path(\"..\") / settings.CONF_SOURCE)\n",
    "conf_loader = OmegaConfigLoader(conf_source=conf_path)\n",
    "GOOGLE_API_KEY = conf_loader[\"credentials\"][\"google_api_credentials\"][\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950e3c7-1c5a-45ca-92f3-389b670e973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv: dict[str, t.Any] = catalog.load(\"resume\")  # noqa: F821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c69b1-6cde-4c60-aca1-b1a4b8249327",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda52fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = \"es\"\n",
    "\n",
    "# The selected topic.\n",
    "#  Recomended topics: \"work\", \"certificates\", \"publications\", \"projects\"\n",
    "TOPIC = \"work\"\n",
    "\n",
    "# Number maximum of experiences to generate for the selected topic.\n",
    "# Recommended values:\n",
    "#  - work: 3\n",
    "#  - certificates: 2\n",
    "#  - publications: 2\n",
    "#  - projects: 2\n",
    "N_MAX_EXP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df000c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliasing, only for readability\n",
    "type TopicName = str\n",
    "type TopicDict = dict[str, str | list[str]]\n",
    "type Resume = dict[TopicName, TopicDict]\n",
    "type Document = str\n",
    "type Documents = list[Document]\n",
    "type IDs = list[str]\n",
    "\n",
    "\n",
    "class DocumentsIDs(t.TypedDict):\n",
    "    documents: Documents\n",
    "    ids: IDs\n",
    "\n",
    "\n",
    "GENERATE_ID_DICT: dict[TopicName, t.Callable[[TopicDict], str]] = {\n",
    "    \"work\": lambda item: f\"{item['name']}.{item['position']}\",\n",
    "    \"certificates\": lambda item: f\"{item['issuer']}.{item['name']}\",\n",
    "    \"publications\": lambda item: f\"{item['publisher']}.{item['name']}\",\n",
    "    \"projects\": lambda item: item[\"name\"],\n",
    "    \"volunteer\": lambda item: item[\"position\"],\n",
    "    \"education\": lambda item: f\"{item['studyType']}.{item['area']}\",\n",
    "    \"basics\": lambda item: item[\"name\"],\n",
    "    \"awards\": lambda item: f\"{item['title']}.{item['awarder']}\",\n",
    "    \"skills\": lambda item: item[\"name\"],\n",
    "    \"languages\": lambda item: item[\"language\"],\n",
    "    \"interests\": lambda item: item[\"name\"],\n",
    "    \"references\": lambda item: item[\"name\"],\n",
    "}\n",
    "\n",
    "\n",
    "def decorate_gen_id(\n",
    "    topic: TopicName, id_fn: t.Callable[[TopicDict], str]\n",
    ") -> t.Callable[[TopicDict], str]:\n",
    "    \"\"\"\n",
    "    Decorator to generate IDs for documents.\n",
    "\n",
    "    It adds the topic name to the ID generated by the provided function. It also\n",
    "    replaces spaces, dashes, commas, and colons with underscores. This is useful\n",
    "    for creating unique IDs for documents in a structured format.\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(item: TopicDict) -> str:\n",
    "        id_fn_result = id_fn(item)\n",
    "\n",
    "        # Clear any special characters from the ID\n",
    "        id_fn_result = (\n",
    "            id_fn_result.replace(\" \", \"_\")\n",
    "            .replace(\"-\", \"_\")\n",
    "            .replace(\",\", \"_\")\n",
    "            .replace(\":\", \"_\")\n",
    "        )\n",
    "        id_fn_result = (\n",
    "            id_fn_result.replace(\"(\", \"\")\n",
    "            .replace(\")\", \"\")\n",
    "            .replace(\"'\", \"\")\n",
    "            .replace('\"', \"\")\n",
    "        )\n",
    "        id_fn_result = id_fn_result.replace(\n",
    "            \"..\", \".\"\n",
    "        )  # Chromadb do not accept double dots\n",
    "\n",
    "        # Clear special characters\n",
    "        id_fn_result = (\n",
    "            id_fn_result.replace(\"á\", \"a\")\n",
    "            .replace(\"é\", \"e\")\n",
    "            .replace(\"í\", \"i\")\n",
    "            .replace(\"ó\", \"o\")\n",
    "            .replace(\"ú\", \"u\")\n",
    "        )\n",
    "        id_fn_result = (\n",
    "            id_fn_result.replace(\"Á\", \"A\")\n",
    "            .replace(\"É\", \"E\")\n",
    "            .replace(\"Í\", \"I\")\n",
    "            .replace(\"Ó\", \"O\")\n",
    "            .replace(\"Ú\", \"U\")\n",
    "        )\n",
    "        id_fn_result = (\n",
    "            id_fn_result.replace(\"ñ\", \"n\")\n",
    "            .replace(\"ü\", \"u\")\n",
    "            .replace(\"Ñ\", \"N\")\n",
    "            .replace(\"Ü\", \"U\")\n",
    "        )\n",
    "\n",
    "        return topic + \".\" + id_fn_result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "GENERATE_ID_DICT = {\n",
    "    topic: decorate_gen_id(topic, id_fn) for topic, id_fn in GENERATE_ID_DICT.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303529c7-6953-4b1b-acc4-266d74f52eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def create_documents(resume: Resume) -> dict[TopicName, DocumentsIDs]:\n",
    "    \"\"\"Create documents and ids for each topic in the resume.\n",
    "\n",
    "    Args:\n",
    "        resume (Resume): Resume dictionary with topics and items.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Raises an exception if an unknown topic is encountered.\n",
    "\n",
    "    Returns:\n",
    "        dict[TopicName, DocumentsIDs]: A dictionary containing documents and\n",
    "            their ids for each topic.\n",
    "    \"\"\"\n",
    "\n",
    "    def fix_accents(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Fixes accents in the text by replacing hex codes with their\n",
    "        corresponding characters.\n",
    "        \"\"\"\n",
    "        text = text.replace(r\"\\xE1\", \"á\")\n",
    "        text = text.replace(r\"\\xE9\", \"é\")\n",
    "        text = text.replace(r\"\\xED\", \"í\")\n",
    "        text = text.replace(r\"\\xF3\", \"ó\")\n",
    "        text = text.replace(r\"\\xF1\", \"ñ\")\n",
    "\n",
    "        return text\n",
    "\n",
    "    documents_dict: dict[TopicName, DocumentsIDs] = dict()\n",
    "\n",
    "    for topic_name, topic in resume.items():\n",
    "\n",
    "        # Create an empty list of documents and ids\n",
    "        documents_ids = DocumentsIDs(documents=[], metadata=dict(), ids=[])\n",
    "        for item in topic:\n",
    "\n",
    "            # Generate document for each item\n",
    "            item_dump = yaml.dump(item, default_flow_style=False, width=float(\"inf\"))\n",
    "            item_parsed = fix_accents(item_dump)\n",
    "            item_parsed = f\"topic_name: {topic_name}\\n\" + item_parsed\n",
    "            documents_ids[\"documents\"].append(item_parsed)\n",
    "\n",
    "            # Generate id for each item\n",
    "            id_func = GENERATE_ID_DICT.get(topic_name, None)\n",
    "\n",
    "            if id_func is None:\n",
    "                raise Exception(f\"Unknow topic: {topic_name = }, {item = }\")\n",
    "\n",
    "            id = id_func(item)\n",
    "\n",
    "            documents_ids[\"ids\"].append(id)\n",
    "\n",
    "        # Finally, add the documents and ids to the main dict\n",
    "        documents_dict[topic_name] = documents_ids\n",
    "\n",
    "    return documents_dict\n",
    "\n",
    "\n",
    "documents_ids = create_documents(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc128c7-7bb4-40c4-90c7-503d0f8b017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "def is_retriable(e):\n",
    "    return isinstance(e, genai.errors.APIError) and e.code in {429, 503}\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, document_mode: bool = True) -> None:\n",
    "        self.embedding_task: str = (\n",
    "            \"retrieval_document\" if document_mode else \"retrieval_query\"\n",
    "        )\n",
    "        self.model: str = \"text-embedding-004\"\n",
    "\n",
    "    @retry.Retry(predicate=is_retriable)\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "\n",
    "        response = client.models.embed_content(\n",
    "            model=self.model,\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(task_type=self.embedding_task),\n",
    "        )\n",
    "        return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ae309-c42a-4640-932c-70ac62e73de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "DB_NAME = \"resume\"\n",
    "\n",
    "DB_PATH = Path(\"..\") / \"data\" / \"03_primary\" / \"chromadb\"\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def create_chromadb(\n",
    "    embed_fn: EmbeddingFunction,\n",
    "    documents_ids: DocumentsIDs,\n",
    "    topic_name: str,\n",
    "    language: str = LANG,\n",
    ") -> chromadb.Collection:\n",
    "    \"\"\"Create a ChromaDB collection and add documents to it.\n",
    "\n",
    "    This function creates a ChromaDB collection with the specified name and\n",
    "    embedding function. It then adds the documents and their IDs to the\n",
    "    collection.\n",
    "\n",
    "    Args:\n",
    "        embed_fn (EmbeddingFunction): The embedding function to use for the documents.\n",
    "        documents_ids (dict[TopicName, DocumentsIDs]): A dictionary mapping topic names to document IDs.\n",
    "        topic_name (str): The name of the topic for the collection.\n",
    "        language (str): The language of the documents.\n",
    "\n",
    "    Returns:\n",
    "        chromadb.Collection: The created (or retrieved) ChromaDB collection.\n",
    "    \"\"\"\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(path=str(DB_PATH))\n",
    "\n",
    "    name_collection = (\n",
    "        f\"{DB_NAME}.{topic_name}\"\n",
    "        if language == \"en\"\n",
    "        else f\"{DB_NAME}.{language}.{topic_name}\"\n",
    "    )\n",
    "\n",
    "    db = chroma_client.get_or_create_collection(\n",
    "        name=name_collection, embedding_function=embed_fn\n",
    "    )\n",
    "\n",
    "    # See if the documents are already in the database\n",
    "    original_db_ids = set(db.get(include=[])[\"ids\"])\n",
    "    diff_ids = set(documents_ids[\"ids\"]) - original_db_ids\n",
    "\n",
    "    if len(diff_ids) > 0:\n",
    "        # If the documents are not already in the database, add them\n",
    "        print(  # noqa: T201\n",
    "            f\"Adding {len(documents_ids['ids'])} documents to {name_collection}\"\n",
    "        )\n",
    "\n",
    "        db.add(documents=documents_ids[\"documents\"], ids=documents_ids[\"ids\"])\n",
    "\n",
    "    return db\n",
    "\n",
    "\n",
    "if (docs_ids_topic := documents_ids.get(TOPIC, None)) is None:\n",
    "    raise Exception(f\"Topic {TOPIC} not found in documents_ids\")\n",
    "\n",
    "db = create_chromadb(\n",
    "    embed_fn=GeminiEmbeddingFunction(document_mode=True),\n",
    "    documents_ids=docs_ids_topic,\n",
    "    topic_name=TOPIC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8019c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.get(include=[])[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc71bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_ids[\"work\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e754741-24fe-4946-8db1-98c11660c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESCRIPTION = \"\"\"\n",
    "En Clay Fintech estamos construyendo productos que integran inteligencia artificial desde el corazón. Creemos que esta tecnología puede transformar tanto nuestros procesos internos como la forma en que ayudamos a nuestros clientes.\n",
    "\n",
    "Estamos buscando a alguien que se sume a este camino desde etapas tempranas, con muchas ganas de aprender, aportar ideas, y construir junto a nosotros. Si te interesa el mundo de la IA, los datos, y el desarrollo de software, ¡este rol es para ti!\n",
    "\n",
    "\n",
    "🔧 Lo que harás\n",
    "\n",
    "Desarrollarás herramientas internas y soluciones para clientes usando tecnologías modernas.\n",
    "Colaborarás en la creación de agentes de IA, integraciones con APIs, y pipelines de datos.\n",
    "Probarás nuevas formas de aplicar modelos de lenguaje (LLMs) y otros enfoques de IA.\n",
    "Participarás activamente en un equipo técnico que valora la autonomía, el aprendizaje continuo y el buen feedback\n",
    " \n",
    "\n",
    "🌱 Qué buscamos (no necesitas tener todo)\n",
    "\n",
    "Experiencia programando en Python (proyectos personales, bootcamps, freelance o universidad).\n",
    "Curiosidad real por la inteligencia artificial y el trabajo con datos.\n",
    "Conocimientos básicos de bases de datos (SQL o NoSQL).\n",
    "Buena comunicación, ganas de aprender y trabajar en equipo.\n",
    "Bonus (no excluyente): experiencia con alguna de estas herramientas o conceptos: Langchain, LlamaIndex, embeddings o retrieval MongoDB PostgreSQL AWS (S3, Lambda, Step Functions)\n",
    "🎁 Beneficios 🏖️ 5 semanas de vacaciones al año (sí, ¡cinco!)\n",
    "🕓 Horario flexible y trabajo remoto desde cualquier parte de Chile\n",
    "🧑‍⚕️ Seguro de salud y dental complementario\n",
    "📈 Reajuste de sueldo por IPC cada 6 meses\n",
    "🎂 Día libre en tu cumpleaños (y medio día libre para el de tus hijos)\n",
    "📚 Tarde libre al mes para recargar energías\n",
    "📝 3 días administrativos para trámites personales\n",
    "👥 Ambiente de trabajo buena onda, con foco en el aprendizaje, la colaboración y el crecimiento\n",
    "\n",
    "📍 Remoto desde Chile (también puedes trabajar desde nuestra oficina si prefieres)\n",
    "\n",
    "Postula aquí.\n",
    "\"\"\"  # noqa: W293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7388d-ade9-4265-b4fe-f83acc19bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrival_query(\n",
    "    query: str,\n",
    "    embed_fn: EmbeddingFunction,\n",
    "    db: chromadb.Collection,\n",
    "    max_exp: int = 5,\n",
    "    window: int = 2,\n",
    ") -> list[str]:\n",
    "    \"\"\"Query the Chroma DB and return the top passages.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string.\n",
    "        embed_fn (EmbeddingFunction): The embedding function to use.\n",
    "        db (chromadb.Collection): The Chroma DB collection to query.\n",
    "        max_exp (int, optional): The maximum number of passages to return. Defaults to 5.\n",
    "        window (int, optional): The number of passages to include in each window. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of passages that match the query.\n",
    "    \"\"\"\n",
    "    n_results = db.count()\n",
    "    result = db.query(query_texts=[query], n_results=min(n_results, max_exp + window))\n",
    "    [all_passages] = result[\"documents\"]\n",
    "    return all_passages\n",
    "\n",
    "\n",
    "all_passages = retrival_query(\n",
    "    query=DESCRIPTION,\n",
    "    embed_fn=GeminiEmbeddingFunction(document_mode=False),\n",
    "    db=db,\n",
    "    max_exp=N_MAX_EXP,\n",
    "    window=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c548d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_languages = [\"es\", \"en\"]\n",
    "type Language = t.Literal[*supported_languages]\n",
    "\n",
    "contents = [\"example\", \"prompt\", \"quit_msg\"]\n",
    "type Content = t.Literal[*contents]\n",
    "\n",
    "\n",
    "# Dictionary that stores content in different languages\n",
    "content: dict[Language, dict[Content, str]] = {\n",
    "    lang: dict() for lang in supported_languages\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3696de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit message in different languages\n",
    "content[\"en\"][\"quit_msg\"] = \"To exit, enter 'q'\"\n",
    "content[\"es\"][\"quit_msg\"] = \"Para salir, ingrese 'q'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f67573-bff4-47ea-b5cd-d64cc3b35cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example result for different languages\n",
    "\n",
    "content[\"en\"][\"example\"] = \"\"\"\n",
    "## Position Name / Title: Research Assistant\n",
    "- Company Name / Business Name: CENIA\n",
    "- Industry type: Information and Research\n",
    "- Job Field: Education, Teaching and Research\n",
    "- Sub-Area of Work: Research and Development\n",
    "\n",
    "### Original Description\n",
    "\n",
    "[ORIGINAL DESCRIPTION]\n",
    "\n",
    "### Modified description\n",
    "\n",
    "[SHORT DESCRIPTION]\n",
    "- [TASK PERFORMED 1]\n",
    "- ...\n",
    "\n",
    "### Changes made\n",
    "\n",
    "- Keywords used: [KEYWORD 1], ...\n",
    "- Brief explanation of the changes made: [EXPLANATION OF CHANGES].\n",
    "\n",
    "\n",
    "Shall we continue [Y/n]?\n",
    "\"\"\"\n",
    "\n",
    "content[\"es\"][\"example\"] = \"\"\"\n",
    "## Nombre del puesto / Título: Asistente de Investigación\n",
    "- Nombre de empresa / Negocio: CENIA\n",
    "- Tipo de industria: Información e Investigación\n",
    "- Área de trabajo: Educación, Docencia e Investigación\n",
    "- Subárea de trabajo: Investigación y Desarrollo\n",
    "\n",
    "### Descripción original\n",
    "\n",
    "[DESCRIPCIÓN ORIGINAL]\n",
    "\n",
    "### Descripción modificada\n",
    "\n",
    "[PEQUEÑA DESCRIPCIÓN]\n",
    "- [TAREA REALIZADA 1]\n",
    "- ...\n",
    "\n",
    "### Cambios realizados\n",
    "\n",
    "- Palabras clave utilizadas: [PALABRA CLAVE 1], ...\n",
    "- Breve explicación de los cambios realizados: [EXPLICACIÓN DE CAMBIOS]\n",
    "\n",
    "\n",
    "¿Continuamos? [Y/n]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for the model\n",
    "\n",
    "content[\"en\"][\"prompt\"] = r\"\"\"\n",
    "You are an expert in job interviews, with deep knowledge of the applicant tracking system (ATS), and you are capable of identifying keywords from a job description. I need you to analyze the job description and the experiences listed below, and modify the experiences so that they align with the keywords from the job description. This way, the experiences will be 100% ATS-compatible.\n",
    "\n",
    "It is important that the description is:\n",
    "- ATS-friendly.\n",
    "- Concise.\n",
    "- Persuasive to the recruiter.\n",
    "- Aligned with my personal brand.\n",
    "- Written in active voice: Developed, designed, executed...\n",
    "\n",
    "Only return what is necessary—do not add any extra or filler words.\n",
    "\n",
    "Start by listing the identified keywords, followed by the top {n_max_exp} most relevant professional experiences, listed in reverse chronological order based on their start date. In a separate section, list the other experiences that were not selected. I ONLY WANT THE JOB TITLE AND COMPANY NAME.\n",
    "\n",
    "EXAMPLE: \"\n",
    "** KEYWORDS: ** [KEYWORD 1], [KEYWORD 2], ...\n",
    "** HIGHLIGHTED EXPERIENCES: **\n",
    "- ([START DATE] - [END DATE]) [JOB TITLE 1], [COMPANY NAME 1]\n",
    "- ...\n",
    "** NON-SELECTED EXPERIENCES: **\n",
    "- ([START DATE] - [END DATE]) [JOB TITLE 1], [COMPANY NAME 1]\n",
    "- ...\n",
    "\n",
    "Do you possess all the skills related to the identified keywords? Does any experience need to be modified?\n",
    "\"\n",
    "\n",
    "As a reply to your message, I will let you know which experiences I have that match the keywords and whether I feel the experiences align with what I want. I will ask you to modify an experience if needed.\n",
    "\n",
    "Once I respond, present the experience in the format shown below. IT IS IMPORTANT THAT YOU ONLY SHOW ONE EXPERIENCE AT A TIME. MENTION WHICH KEYWORDS YOU USED TO ADAPT THE EXPERIENCE AND MAKE IT MORE IMPACTFUL. There's no need to copy and paste the original experience description—you may modify or remove content if you believe it improves clarity or relevance. Be sure to mention what changes you made, what you added, and what you removed.\n",
    "\n",
    "I will decide whether the description is appropriate and request changes if needed. Once that experience is complete, we will proceed to the next one.\n",
    "\n",
    "EXPERIENCE FORMAT EXAMPLE: \"{example}\"\n",
    "\n",
    "JOB DESCRIPTION: \"{description}\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "content[\"es\"][\"prompt\"] = r\"\"\"\n",
    "Eres un experto en entrevistas de trabajo, conociendo a detalle el applicant tracking system, y eres capaz de reconocer las palabras clave a partir de la descripción de una oferta de trabajo. Necesito que, a partir de la descripción de la oferta de trabajo, y de las experiencias incluidas más abajo, seas capaz de  modificar las experiencias para que calcen con las palabras clave de la descripción. De esta manera, que las experiencias sean 100% compatibles con el applicant tracking system.\n",
    "\n",
    "Es importante que la descripción sea:\n",
    "- Compatible con ATS.\n",
    "- Que tenga un contenido conciso.\n",
    "- Que resulte convincente para el reclutador.\n",
    "- Que sea congruente con mi marca personal.\n",
    "- Que utilice la voz activa: Programé, diseñé, ejecuté...\n",
    "\n",
    "Solo retorna lo necesario, no agregues palabras de más.\n",
    "\n",
    "Empieza enlistando las palabras claves detectadas y enlista las {n_max_exp} experiencias más destacables, en orden cronológico decreciente con respecto a la fecha de inicio. En una sección aparte, enlista las otras experiencias que no fueron seleccionadas. INTENTA QUE EL NOMBRE SEA DECRIPTIVO, Y QUE AYUDE A DIFERENCIARSE ENTRE LAS DEMÁS EXPERIENCIAS. AGREGA UNA DESCRIPCIÓN MUY BREVE, DE UNA LÍNEA MÁXIMO.\n",
    "\n",
    "EJEMPLO: \"\n",
    "** PALABRAS CLAVES: ** [PALABRA 1], [PALABRA 2], ...\n",
    "** EXPERIENCIAS DESTACADAS: **\n",
    "- ([FECHA DE INICIO] - [FECHA DE FIN]) [NOMBRE]: [DESCRIPCIÓN]\n",
    "- ...\n",
    "** EXPERIENCIAS NO SELECCIONADAS: **\n",
    "- ([FECHA DE INICIO] - [FECHA DE FIN]) [NOMBRE]: [DESCRIPCIÓN]\n",
    "- ...\n",
    "\n",
    "¿Posees todas las habilidades de las palabras claves? ¿Es necesario modificar\n",
    "alguna experiencia?\n",
    "\"\n",
    "\n",
    "Como respuesta a tu mensaje, te responderé cuáles son las experiencias que tengo con las palabras claves, y también si considero que las experiencias laborales están acorde a lo que deseo. Te pediré cambiar alguna experiencia si se da el caso. NO RESPONDAS LAS ÚLTIMAS PREGUNTAS DEL EJEMPLO, SOLO DEBES MOSTRAR LAS PREGUNTAS. YO RESPONDERÉ A LAS PREGUNTAS.\n",
    "\n",
    "Una vez que haya respondido, presentame la experiencia en el formato que te entrego más abajo. ES IMPORTANTE QUE MUESTRES SOLO UNA ÚNICA EXPERIENCIA. MENCIONA QUÉ PALABRAS CLAVE UTILIZASTE PARA MODIFICAR LA OFERTA Y DARLE MAYOR IMPACTO. No es necesario copiar y pegar la descripción de la experiencia original, puedes modificar o quitar experiencias si lo consideras necesario. Recuerda mencionar qué cambios hiciste, qué agregaste y qué quitaste.\n",
    "\n",
    "Yo decidiré si la descripción es adecuada, donde te pediré modificaciones si es necesario. Una vez que termine con esa experiencia, procederemos a ver la siguiente experiencia.\n",
    "\n",
    "EJEMPLO DE FORMATO DE EXPERIENCIA: \"{example}\"\n",
    "\n",
    "DESCRIPCIÓN DE LA OFERTA: \"{description}\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_lang = content[LANG]\n",
    "\n",
    "prompt = content_lang[\"prompt\"].format(\n",
    "    example=content_lang[\"example\"], description=DESCRIPTION, n_max_exp=N_MAX_EXP\n",
    ")\n",
    "\n",
    "for passage in all_passages:\n",
    "    passage_oneline = passage.replace(\"\\n\", \"  \\n\")\n",
    "    prompt += \"EXPERIENCE: \" + passage_oneline + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ed367-9513-4579-80d1-94a889c7d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = types.GenerateContentConfig(temperature=0.8, top_p=0.95, top_k=30)\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\", history=[], config=config)\n",
    "\n",
    "response = chat.send_message(prompt)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f66a8-f3c3-4d9c-b634-b2a39ea54b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(content_lang[\"quit_msg\"])  # noqa: T201\n",
    "    msg: str = input(\"> \")\n",
    "    if msg.lower() == \"q\":\n",
    "        break\n",
    "    if not msg:\n",
    "        msg = \"Y\"\n",
    "    print(\"\")  # noqa: T201\n",
    "    response = chat.send_message(msg)\n",
    "    print(response.text)  # noqa: T201"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
